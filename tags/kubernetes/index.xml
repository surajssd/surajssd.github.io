<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernetes on Suraj Deshmukh</title>
    <link>https://suraj.io/tags/kubernetes/</link>
    <description>Recent content in kubernetes on Suraj Deshmukh</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 04 Sep 2021 13:30:07 +0530</lastBuildDate><atom:link href="https://suraj.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Certified Kubernetes Security Specialist CKS exam tips</title>
      <link>https://suraj.io/post/2021/09/cks-tips/</link>
      <pubDate>Sat, 04 Sep 2021 13:30:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/09/cks-tips/</guid>
      <description>I recently cleared the CKS certification exam. So it is incumbent upon me to help you navigate this stress-bound exam. All the tips that are provided are either from accrued knowledge or from personal experience.
Study Material During the study of CKA almost three years ago, I studied everything from the documentation. Back then, the documentation had less content hence it was comprehensible. But now, to go through the entire documentation was not practical.</description>
    </item>
    
    <item>
      <title>How to &#39;automatically&#39; generate a self-signed TLS certificate for Kubernetes Admission Webhook Servers?</title>
      <link>https://suraj.io/post/2021/06/automatic-cert-gen/</link>
      <pubDate>Fri, 25 Jun 2021 09:00:00 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/06/automatic-cert-gen/</guid>
      <description>The previous blog talked about generating self-signed certificates using a binary. It was a manual, cumbersome process where you had to generate the certificates using a tool, embed them into a Kubernetes Secret via Helm chart, and then use it. There is a better way of doing it! Which is what this blog will discuss.
We will use a Helm chart, which has a couple of Kubernetes Jobs that generates the self-signed certificate, embed them in a Kubernetes Secret and finally update the ValidatingWebhookConfiguration or MutatingWebhookConfiguration of your choice.</description>
    </item>
    
    <item>
      <title>How to import &#39;any&#39; Kubernetes package into your project?</title>
      <link>https://suraj.io/post/2021/05/k8s-import/</link>
      <pubDate>Sun, 30 May 2021 09:40:00 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/05/k8s-import/</guid>
      <description>The client libraries that Kubernetes ships are meant to be imported, and you definitely don&amp;rsquo;t need this post explaining how to import them in your Golang based project. A simple go get ... should do the trick. But, what about the packages that are not meant to be imported? Or the ones that cannot be imported because of &amp;ldquo;technical reasons&amp;rdquo; ? Could you simply add them to your import statements in the .</description>
    </item>
    
    <item>
      <title>How to generate a self-signed TLS certificate for Kubernetes Admission Webhook Servers?</title>
      <link>https://suraj.io/post/2021/05/self-sign-k8s-cert/</link>
      <pubDate>Fri, 21 May 2021 15:33:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/05/self-sign-k8s-cert/</guid>
      <description>UPDATE: There is a way to generate these certificates automatically. To find out how, read this post.
 If you are writing a webhook server for Kubernetes Admission Controllers like ValidatingAdmissionWebhooks or MutatingAdmissionWebhooks, you must expose it over HTTPS. To run these servers on HTTPS, you need TLS certificates. There are solutions available which you can use to solve this problem, first and foremost that comes to my mind is cert-manager.</description>
    </item>
    
    <item>
      <title>Mitigation of: Access Any Kubernetes Secret</title>
      <link>https://suraj.io/post/2021/05/access-k8s-secrets-mitigation/</link>
      <pubDate>Thu, 20 May 2021 08:47:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/05/access-k8s-secrets-mitigation/</guid>
      <description>In the previous blog, we discussed how any user without RBAC access to a Kubernetes secret can use a trick to access that secret. To mitigate that problem, we will use a validating admission webhook. But before looking at what sorcery this validating admission webhook server is, let us understand how Kubernetes handles the API requests.
What are admission controllers? All requests going to the Kubernetes API server go through the following four steps:</description>
    </item>
    
    <item>
      <title>Access Any Kubernetes Secret</title>
      <link>https://suraj.io/post/2021/05/access-k8s-secrets/</link>
      <pubDate>Sat, 08 May 2021 12:17:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/05/access-k8s-secrets/</guid>
      <description>Photo by Kyle Glenn on Unsplash.
You can gain access to any secret that you want in Kubernetes even if you don&amp;rsquo;t have RBAC permissions to get, list or view that secret. All you need is permission that allows you to do anything on pods and an ability to guess the names of secrets. With these two ingredients, here is how you can access any secret out there.
Nasty User Here is a user called nastyuser who can only do stuff on pod objects.</description>
    </item>
    
    <item>
      <title>Monitor your PC with Prometheus Grafana stack</title>
      <link>https://suraj.io/post/2021/03/node-monitor/</link>
      <pubDate>Fri, 02 Apr 2021 07:07:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/03/node-monitor/</guid>
      <description>How do you monitor your own computer? Of course, using Prometheus, node-exporter and Grafana. You might ask why would you wanna do that when you can simply use the operating system provided, &amp;ldquo;System Monitor&amp;rdquo;. Well, yes, you can use that. But the data you get from the OS System Monitor is coarse-grained. OS system monitor is not configurable, but this stack is.
It is like running htop but where you can go back in history, unlike htop, which only shows the current state.</description>
    </item>
    
    <item>
      <title>Kubernetes The Hard Way in &#34;Vagrant&#34;?</title>
      <link>https://suraj.io/post/2021/03/kthw-vagrant/</link>
      <pubDate>Tue, 23 Mar 2021 07:07:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/03/kthw-vagrant/</guid>
      <description>If you are studying for the Certified Kubernetes Administrator (CKA) exam, you might have come across folks recommending Kelsey Hightower&amp;rsquo;s Kubernetes the Hard Way. It is an excellent first step for someone who has no idea about the components that form a Kubernetes cluster. As the name suggests, it is created so that you learn the Kubernetes building blocks the &amp;ldquo;hard way&amp;rdquo;.
But all that can be intimidating to someone who hasn&amp;rsquo;t played with Kubernetes ever.</description>
    </item>
    
    <item>
      <title>Enable TLS bootstrapping in a Kubernetes cluster</title>
      <link>https://suraj.io/post/2021/02/k8s-bootstrap-token/</link>
      <pubDate>Sat, 06 Feb 2021 10:25:41 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/02/k8s-bootstrap-token/</guid>
      <description>Photo by Jordan Harrison from Unsplash.
 This blog is a recap of my old blog &amp;ldquo;Add new node to Kubernetes cluster with bootstrap token&amp;rdquo;. Like the aforementioned blog, we will look at how to enable TLS bootstrapping on an existing Kubernetes cluster at control plane level and add a new node (or modify existing ones) to the cluster using bootstrap tokens. At the end of this blog, you will learn what specific steps to take to enable TLS bootstrapping on any custom-built Kubernetes cluster.</description>
    </item>
    
    <item>
      <title>Kubernetes Cluster using Kubeadm on Flatcar Container Linux</title>
      <link>https://suraj.io/post/2021/01/kubeadm-flatcar/</link>
      <pubDate>Fri, 29 Jan 2021 22:02:41 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/01/kubeadm-flatcar/</guid>
      <description>Image Source: Flatcar Linux is now open to the public.
This blog shows a simple set of commands to install a Kubernetes cluster on Flatcar Container Linux based machines using Kubeadm.
You might wonder why this blog when one can go to the official documentation and follow the steps? Yep, you are right. You can choose to do that. But this blog has a collection of actions specific to Flatcar Container Linux.</description>
    </item>
    
    <item>
      <title>Exec in container environment</title>
      <link>https://suraj.io/post/2021/01/shell-exec/</link>
      <pubDate>Sat, 23 Jan 2021 10:10:41 +0530</pubDate>
      
      <guid>https://suraj.io/post/2021/01/shell-exec/</guid>
      <description>If you use exec in your container script, then the container or Kubernetes pod might exit after the command that is exec-ed into has exited. But if that&amp;rsquo;s what you wanted, then it&amp;rsquo;s okay. This blog tries to explain how to pass the signals to the applications, how they work differently when invoked uniquely and what to do if the application does handle them.
What are the &amp;ldquo;Signals&amp;rdquo;? Signals are messages one process can send to another process, mostly used in UNIX like operating systems.</description>
    </item>
    
    <item>
      <title>Mental models for understanding Kubernetes Pod Security Policy</title>
      <link>https://suraj.io/post/mental-models-for-understanding-kubernetes-pod-security-policy/</link>
      <pubDate>Sat, 16 Jan 2021 13:10:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/mental-models-for-understanding-kubernetes-pod-security-policy/</guid>
      <description>PodSecurityPolicy (PSP) is hard to get right in the first attempt. There has never been a situation when I haven&amp;rsquo;t banged my head to get it working on the cluster. It is a frustrating experience, but it is one of the essential security features of Kubernetes. Some applications have started shipping the PSP configs with their helm charts, but if a helm chart does not ship a PSP config, it must be handcrafted by the cluster-admin to make the application work reliably in the cluster.</description>
    </item>
    
    <item>
      <title>How to gracefully kill Kubernetes Jobs with a sidecar?</title>
      <link>https://suraj.io/post/how-to-gracefully-kill-kubernetes-jobs-with-a-sidecar/</link>
      <pubDate>Sat, 29 Aug 2020 15:33:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/how-to-gracefully-kill-kubernetes-jobs-with-a-sidecar/</guid>
      <description>Have you ever had a sidecar in your Kubernetes Job? If no, then trust me that you are lucky. If yes, then you will have the frustration of your life. The thing is Kubernetes Jobs are meant to exit on completion. But if you have a long-running sidecar, then that might twist things for Kubernetes and in turn of you.
Why would you even want a sidecar for Job? Well, one of the most prevalent use case is when using service mesh proxy.</description>
    </item>
    
    <item>
      <title>Use Configmap for Scripts</title>
      <link>https://suraj.io/post/use-configmap-for-scripts/</link>
      <pubDate>Sat, 22 Aug 2020 21:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/use-configmap-for-scripts/</guid>
      <description>We generally use some sort of scripts in application container images. They serve various purposes. Some scripts might do an initial setup before the application starts, others may have the whole logic of the container image, etc. Whatever the goal may be the general pattern is to copy the script into the container image, build the image and then the script is available when you consume the image.
Cons of the Traditional Method The round trip time during development and testing of such script is very long.</description>
    </item>
    
    <item>
      <title>Being Productive with Kubectl</title>
      <link>https://suraj.io/post/being-productive-with-kubectl/</link>
      <pubDate>Sun, 02 Aug 2020 16:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/being-productive-with-kubectl/</guid>
      <description>This blog will showcase my productivity tips with kubectl . This does not venture into any plugins per se. But only using bash aliases to achieve it.
Bash Aliases # k8s alias alias k=kubectl alias kg=&amp;#34;kubectl get&amp;#34; alias kgp=&amp;#34;kubectl get pods&amp;#34; alias kgs=&amp;#34;kubectl get services&amp;#34; alias kge=&amp;#34;kubectl get events&amp;#34; alias kgpvc=&amp;#34;kubectl get pvc&amp;#34; alias kgpv=&amp;#34;kubectl get pv&amp;#34; alias kd=&amp;#34;kubectl describe&amp;#34; alias kl=&amp;#34;kubectl logs -f&amp;#34; alias kc=&amp;#34;kubectl create -f&amp;#34; I have above aliases setup in the ~/.</description>
    </item>
    
    <item>
      <title>How to backup and restore Prometheus?</title>
      <link>https://suraj.io/post/how-to-backup-and-restore-prometheus/</link>
      <pubDate>Fri, 31 Jul 2020 19:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/how-to-backup-and-restore-prometheus/</guid>
      <description>This blog will show you how to take a backup from a running Prometheus and restore it in some other Prometheus instance. You might ask why would you even want to do something like that? Well, sometimes you want the Prometheus metrics because they were collected for some particular purpose and you want to do some analysis later.
Prerequisites/Assumptions This blog assumes that you have a Prometheus running that is deployed using prometheus-operator in monitoring namespace.</description>
    </item>
    
    <item>
      <title>Watch Container Traffic Without Exec</title>
      <link>https://suraj.io/post/snoop-on-pod-traffic/</link>
      <pubDate>Sat, 06 Jun 2020 20:30:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/snoop-on-pod-traffic/</guid>
      <description>Introduction For the reasons of security, many container deployments nowadays run their workloads in a scratch based image. This form of implementation helps reduce the attack surface since there is no shell to gain access to, especially if someone were to break out of the application.
But for the developers or operators of such applications, it is hard to debug. Since they lack essential tools or even bash for that matter, but the application&amp;rsquo;s debugging ability should not dictate its production deployment and compromise its security posture.</description>
    </item>
    
    <item>
      <title>Enabling Seccomp on your Prometheus Operator and related Pods</title>
      <link>https://suraj.io/post/seccomp-in-kube-state-metrics/</link>
      <pubDate>Tue, 14 Apr 2020 11:57:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/seccomp-in-kube-state-metrics/</guid>
      <description>Seccomp helps us limit the system calls the process inside container can make. And PodSecurityPolicy is the way to enable it on pods in Kubernetes.
Prometheus Operator Prometheus Operator makes it really easy to monitor your Kubernetes cluster. To deploy this behemoth, helm chart is the easiest way to do it.
Almost all the pods that run as a part of Prometheus Operator viz. Prometheus Operator, Prometheus, Alertmanager, Grafana, Kube State Metrics don’t need to run with elevated privileges except Node Exporter.</description>
    </item>
    
    <item>
      <title>Suraj Deshmukh&#39;s talks at conferences</title>
      <link>https://suraj.io/post/surajd-talks-links/</link>
      <pubDate>Mon, 22 Apr 2019 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/surajd-talks-links/</guid>
      <description>PSP and Beyond - Kubernetes Bangalore Meetup June 2021    Hardening Kubernetes by Securing Pods - Rootconf 2019    State of Kubernetes Meetups - DevOpsDays India 2017    Making Kubernetes Simple For Developers - Rootconf 2017    Taking docker-compose to Production - Gophercon 2017 Lightening talk Watch from 55m59s
  </description>
    </item>
    
    <item>
      <title>Kubernetes Bangalore March 2019 Event Report</title>
      <link>https://suraj.io/post/k8s-blr-event-report-2019-03-16/</link>
      <pubDate>Thu, 21 Mar 2019 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/k8s-blr-event-report-2019-03-16/</guid>
      <description>The Kubernetes Bangalore Meetup was organized at Arvind Internet on Feb 16th 2019. The agenda for the meetup was to teach Kubernetes to the beginners.
Meetup agenda can be found here.
The moments from Meetup:
We go online in sometime here https://t.co/FkwgOx0Tm4
&amp;mdash; Kubernetes Bangalore (@k8sBLR) March 16, 2019  .@pmishra1598 kick started the Meetup by explaining what #Kubernetes is! Currently clarifying what a pod is. pic.twitter.com/Ny7bN9c62x
&amp;mdash; Kubernetes Bangalore (@k8sBLR) March 16, 2019  Huge turnout at today&amp;#39;s meetup it&amp;#39;s on 🔥🔥 pic.</description>
    </item>
    
    <item>
      <title>Make static configs available for apiserver in minikube</title>
      <link>https://suraj.io/post/apiserver-in-minikube-static-configs/</link>
      <pubDate>Sun, 20 Jan 2019 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/apiserver-in-minikube-static-configs/</guid>
      <description>If you want to provide extra flags to the kube-apiserver that runs inside minikube how do you do it? You can use the minikube&amp;rsquo;s --extra-config flag with apiserver.&amp;lt;apiserver flag&amp;gt;=&amp;lt;value&amp;gt;, for e.g. if you want to enable RBAC authorization mode you do it as follows:
--extra-config=apiserver.authorization-mode=RBAC So this is a no brainer when doing it for flags whose value can be given right away, like the one above. But what if you want to provide value which is a file path.</description>
    </item>
    
    <item>
      <title>Recreate Kubernetes CVE-2017-1002101</title>
      <link>https://suraj.io/post/cve-2017-1002101-subpath-volume-mount-recreate/</link>
      <pubDate>Mon, 14 Jan 2019 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/cve-2017-1002101-subpath-volume-mount-recreate/</guid>
      <description>A volume mount CVE was discovered in Kubernetes 1.9 and older which allowed access to node file system using emptyDir volume mount using subpath. The official description goes as follows:
 In Kubernetes versions 1.3.x, 1.4.x, 1.5.x, 1.6.x and prior to versions 1.7.14, 1.8.9 and 1.9.4 containers using subpath volume mounts with any volume type (including non-privileged pods, subject to file permissions) can access files/directories outside of the volume, including the host&amp;rsquo;s filesystem.</description>
    </item>
    
    <item>
      <title>Add new Node to k8s cluster with Bootstrap token</title>
      <link>https://suraj.io/post/add-new-k8s-node-bootstrap-token/</link>
      <pubDate>Wed, 24 Oct 2018 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/add-new-k8s-node-bootstrap-token/</guid>
      <description>NOTE: There is an updated version of this blog here.
 Few days back I wrote a blog about adding new node to the cluster using the static token file. The problem with that approach is that you need to restart kube-apiserver providing it the path to the token file. Here we will see how to use the bootstrap token, which is very dynamic in nature and can be controlled by using Kubernetes resources like secrets.</description>
    </item>
    
    <item>
      <title>PodSecurityPolicy on existing Kubernetes clusters</title>
      <link>https://suraj.io/post/psp-on-existing-cluster/</link>
      <pubDate>Tue, 23 Oct 2018 00:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/psp-on-existing-cluster/</guid>
      <description>I enabled PodSecurityPolicy on a minikube cluster by appending PodSecurityPolicy to the apiserver flag in minikube like this:
--extra-config=apiserver.enable-admission-plugins=Initializers,NamespaceLifecycle,\  LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,\  NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,\  ResourceQuota,PodSecurityPolicy Ideally when you have PSP enabled and if you don&amp;rsquo;t define any PSP and authorize it with right RBAC no pod will start in the cluster. But what I saw was that there were some pods still running in kube-system namespace.
$ kubectl -n kube-system get pods NAME READY STATUS RESTARTS AGE coredns-576cbf47c7-g2t8v 1/1 Running 4 5d11h etcd-minikube 1/1 Running 2 5d11h heapster-bn5xp 1/1 Running 2 5d11h influxdb-grafana-qzpv4 2/2 Running 4 5d11h kube-addon-manager-minikube 1/1 Running 2 5d11h kube-controller-manager-minikube 1/1 Running 1 4d20h kube-scheduler-minikube 1/1 Running 2 5d11h kubernetes-dashboard-5bb6f7c8c6-9d564 1/1 Running 8 5d11h storage-provisioner 1/1 Running 7 5d11h Which got me thinking what is wrong with the way PSPs work.</description>
    </item>
    
    <item>
      <title>Road to CKA</title>
      <link>https://suraj.io/post/road-to-cka/</link>
      <pubDate>Sun, 21 Oct 2018 00:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/road-to-cka/</guid>
      <description>I passed CKA exam with 92% marks on 19th October 2018.
A lot of folks are curious about how to prepare and what resources to follow. Here is my list of things to do and list of resources that might help you on successful CKA exam.
The duration of exam is three hours, which is enough time if you do good practice. The exam is pretty straight forward and tests your Kubernetes hands-on knowledge, so whatever you read please try to do it on a real cluster.</description>
    </item>
    
    <item>
      <title>Add new Node to k8s cluster with cert rotation</title>
      <link>https://suraj.io/post/add-new-k8s-node-cert-rotate/</link>
      <pubDate>Tue, 16 Oct 2018 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/add-new-k8s-node-cert-rotate/</guid>
      <description>The setup here is created by following Kubernetes the Hard Way by Kelsey Hightower. So if you are following along in this then do all the setup till the step Bootstrapping the Kubernetes Worker Nodes. In this just don&amp;rsquo;t start the kubelet, start other services like containerd and kube-proxy.
master node Following the docs of TLS Bootstrapping, let&amp;rsquo;s first create the token authentication file. Create a file with following content:</description>
    </item>
    
    <item>
      <title>Adding new worker to existing Kubernetes cluster</title>
      <link>https://suraj.io/post/add-new-k8s-node-manually/</link>
      <pubDate>Sun, 23 Sep 2018 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/add-new-k8s-node-manually/</guid>
      <description>To setup a multi-node Kubernetes cluster just run this script and you will have a cluster with 3 masters and 3 workers.
$ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME worker-0 Ready &amp;lt;none&amp;gt; 1h v1.11.2 192.168.199.20 &amp;lt;none&amp;gt; Ubuntu 18.04.1 LTS 4.15.0-33-generic cri-o://1.11.2 worker-1 Ready &amp;lt;none&amp;gt; 1h v1.11.2 192.168.199.21 &amp;lt;none&amp;gt; Ubuntu 18.04.1 LTS 4.15.0-33-generic cri-o://1.11.2 worker-2 Ready &amp;lt;none&amp;gt; 1h v1.11.2 192.168.199.22 &amp;lt;none&amp;gt; Ubuntu 18.</description>
    </item>
    
    <item>
      <title>Single node Kubernetes Cluster on Fedora with SELinux enabled</title>
      <link>https://suraj.io/post/single-node-k8s-fedora-selinux/</link>
      <pubDate>Tue, 11 Sep 2018 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/single-node-k8s-fedora-selinux/</guid>
      <description>Start a single node fedora machine, using whatever method but I have used this Vagrantfile to do it:
# -*- mode: ruby -*- # vi: set ft=ruby : Vagrant.configure(&amp;#34;2&amp;#34;) do |config| config.vm.define &amp;#34;fedora&amp;#34; do |fedora| fedora.vm.box = &amp;#34;fedora/28-cloud-base&amp;#34; config.vm.hostname = &amp;#34;fedora&amp;#34; end config.vm.provider &amp;#34;virtualbox&amp;#34; do |virtualbox, override| virtualbox.memory = 4096 virtualbox.cpus = 4 end config.vm.provision &amp;#34;shell&amp;#34;, privileged: false, inline: &amp;lt;&amp;lt;-SHELL  echo &amp;#39;127.0.0.1 localhost&amp;#39; | cat - /etc/hosts &amp;gt; temp &amp;amp;&amp;amp; sudo mv temp /etc/hosts SHELL end Now start it and ssh into it:</description>
    </item>
    
    <item>
      <title>HostPath volumes and it&#39;s problems</title>
      <link>https://suraj.io/post/k8s-hostpat-nuke-nodes/</link>
      <pubDate>Mon, 10 Sep 2018 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/k8s-hostpat-nuke-nodes/</guid>
      <description>This post will demonstrate how Kubernetes HostPath volumes can help you get access to the Kubernetes nodes. Atleast you can play with the filesystem of the node on which you pod is scheduled on. You can get access to other containers running on the host, certificates of the kubelet, etc.
I have a 3-master and 3-node cluster and setup using this script, running in a Vagrant environment.
All the nodes are in ready state:</description>
    </item>
    
    <item>
      <title>Access etcd in OpenShift origin</title>
      <link>https://suraj.io/post/accessing-oc-cluster-up-etcd/</link>
      <pubDate>Wed, 11 Jul 2018 01:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/accessing-oc-cluster-up-etcd/</guid>
      <description>How do you access the etcd that is being used by the OpenShift started by oc cluster up or using minishift.
If you are using minishift then get docker environment access of the minishift VM by running following commands.
eval $(minishift docker-env) &amp;amp;&amp;amp; eval $(minishift oc-env) Exec into the container named origin that runs OpenShift and all the needed services.
$ docker exec -it origin bash First install the etcdctl needed to talk to etcd.</description>
    </item>
    
    <item>
      <title>Change namespaces in Kubernetes</title>
      <link>https://suraj.io/post/changing-k8s-ns/</link>
      <pubDate>Mon, 02 Jul 2018 08:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/changing-k8s-ns/</guid>
      <description>There is no easy way to change namespace in Kubernetes using kubectl command line utility. But here are some commands that you can alias in your bashrc file so that it&amp;rsquo;s just a single command that you can use to change the namespace in the Kubernetes cluster.
Change namespace Let&amp;rsquo;s see step by step what goes in to change the namespace. So the first step is to find the context.</description>
    </item>
    
    <item>
      <title>Prometheus with existing application on OpenShift</title>
      <link>https://suraj.io/post/using-prometheus/</link>
      <pubDate>Wed, 04 Apr 2018 08:00:51 +0530</pubDate>
      
      <guid>https://suraj.io/post/using-prometheus/</guid>
      <description>This post is very specific to OpenShift and how you can have an application exposing prometheus metrics to be scraped by a prometheus running in the same cluster.
Requirements Setting up cluster I have done it using the oc cluster up, read about how to do this here. You could also setup a local OpenShift cluster by running minishift, read about setting up minishift here.
Downloading Kedge The configurations defined for setting up this cluster is written in a format that is understood by a tool called Kedge.</description>
    </item>
    
    <item>
      <title>Using private container registries from minikube</title>
      <link>https://suraj.io/post/private-registry-from-minikube/</link>
      <pubDate>Fri, 06 Oct 2017 19:32:33 +0530</pubDate>
      
      <guid>https://suraj.io/post/private-registry-from-minikube/</guid>
      <description>I am doing Kubernetes native development using minikube. And for doing that I had to download a Container image that is available in internally hosted private container registry.
On the configuration side of doing that you will need to create Kubernetes Secret of type docker-registry. And now refer that secret you just created in your Pod manifest under pod.spec.imagePullSecrets. For more info follow the tutorial in Kubernetes docs on Pull an Image from a Private Registry.</description>
    </item>
    
    <item>
      <title>Static Pods using Kubelet on Fedora</title>
      <link>https://suraj.io/post/static-pods/</link>
      <pubDate>Sat, 23 Sep 2017 13:10:14 +0530</pubDate>
      
      <guid>https://suraj.io/post/static-pods/</guid>
      <description>I wanted to try out Standalone Kubelet Tutorial of Kelsey Hightower by myself but I could not follow it as it is, because it was firstly on GCE and secondly it uses CoreOS, but since I am very familiar to Fedora I thought of following that tutorial on it. To get a quick setup of a fresh Fedora machine use Vagrant. I have used Vagrantfile available here.
This blog is only replacement of section Install the Standalone Kubelet in tutorial.</description>
    </item>
    
    <item>
      <title>List of Kubernetes Bangalore meetup event report</title>
      <link>https://suraj.io/post/list-all-k8s-meetups/</link>
      <pubDate>Fri, 01 Sep 2017 15:51:16 +0530</pubDate>
      
      <guid>https://suraj.io/post/list-all-k8s-meetups/</guid>
      <description>List of all the event reports from Kubernetes Bangalore meetup.
 April 2017 May 2017 June 2017 July 2017 Kubernetes 2nd Birthday Celebration August 2017 September 2017 October 2017 November 2017  </description>
    </item>
    
    <item>
      <title>Kubernetes Learning resources</title>
      <link>https://suraj.io/post/k8s-learning-resources/</link>
      <pubDate>Thu, 17 Aug 2017 23:12:18 +0530</pubDate>
      
      <guid>https://suraj.io/post/k8s-learning-resources/</guid>
      <description>Following is the list of all the places you can learn Kubernetes from:
 Scalable Microservices with Kubernetes - Video tutorial Fundamentals of Containers, Kubernetes, and Red Hat OpenShift - Video tutorial Kubernetes By Example - DIY tutorial Learn Kubernetes using Interactive Browser-Based Scenarios - DIY tutorial in your own web browser Interactive Learning Portal for OpenShift - DIY tutorial in your own web browser Kubernetes docs - Textual DIY docs Kubernetes API reference v1.</description>
    </item>
    
    <item>
      <title>Bangalore Kubernetes Meetup July 2017</title>
      <link>https://suraj.io/post/blr-k8s-meetup-july-2017/</link>
      <pubDate>Thu, 13 Jul 2017 22:46:40 +0530</pubDate>
      
      <guid>https://suraj.io/post/blr-k8s-meetup-july-2017/</guid>
      <description>This edition of meetup was held at Nexus Ventures by folks at OpenEBS on July 8th 2017, which started on a lovely Saturday morning.
Kiran Mova set the floor rolling with his talk on Hyperconverged version of OpenEBS with Kubernetes. Where he talked about containerized storage vs traditional storage, instead of building clustering into OpenEBS how they are leveraging Kubernetes&amp;rsquo;s capabilities to do clustering.
He also explained difference between various storage providers viz.</description>
    </item>
    
    <item>
      <title>Bangalore Kubernetes Meetup May 2017</title>
      <link>https://suraj.io/post/blr-k8s-meetup-may-2017/</link>
      <pubDate>Wed, 24 May 2017 02:21:49 +0530</pubDate>
      
      <guid>https://suraj.io/post/blr-k8s-meetup-may-2017/</guid>
      <description>&amp;ldquo;One does not simply deploy containers to production&amp;rdquo;
With the rising craze around the container community in Bangalore and relative lack in awareness around different container technologies like Kubernetes and OpenShift, an effort was made in imparting knowledge in this direction.
So, this time around newbies were targeted for the Kubernetes Meetup.
With the above objective, it was decided to have a Kubernetes 101 workshop at Red Hat Bangalore office on May 21, 2017 to familiarize people with concepts of Kubernetes and OpenShift and their usage and relevance as container orchestration tools for managing application deployments.</description>
    </item>
    
    <item>
      <title>Enabling local development with Kubernetes</title>
      <link>https://suraj.io/post/enabling-local-development-with-k8s/</link>
      <pubDate>Sun, 23 Apr 2017 15:57:07 +0530</pubDate>
      
      <guid>https://suraj.io/post/enabling-local-development-with-k8s/</guid>
      <description>I want to show how you can enable Kubernetes in your day to day development workflow. So that you get the feel of production deployment locally from day 1.
I have a flask application which I am working on. The basic directory structure looks like this:
$ ll total 24 -rw-rw-r--. 1 foo foo 427 Apr 23 16:23 app.py -rw-rw-r--. 1 foo foo 201 Apr 23 16:55 docker-compose.yml -rw-rw-r--. 1 foo foo 363 Apr 23 16:21 Dockerfile -rwxrwxr-x.</description>
    </item>
    
    <item>
      <title>Quick PV for local Kubernetes cluster</title>
      <link>https://suraj.io/post/quick-pv-for-local-k8s/</link>
      <pubDate>Tue, 18 Apr 2017 23:56:15 +0530</pubDate>
      
      <guid>https://suraj.io/post/quick-pv-for-local-k8s/</guid>
      <description>I do lot of Kubernetes related work either on minikube or local OpenShift cluster setup in a VM. Often I need to create a PersistentVolumeClaim a.k.a. pvc. But to use pvc you have to have a PersistentVolume or pv defined.
Enter into the machine running k8s If using minikube you can do
minikube ssh Create a local directory for storage mkdir /tmp/pv0001 chmod 777 /tmp/pv0001 If you are on a machine that has SELinux enabled do the following</description>
    </item>
    
    <item>
      <title>Bangalore Kubernetes Meetup April 2017</title>
      <link>https://suraj.io/post/blr-k8s-meetup-april-2017/</link>
      <pubDate>Sat, 08 Apr 2017 14:31:33 +0530</pubDate>
      
      <guid>https://suraj.io/post/blr-k8s-meetup-april-2017/</guid>
      <description>Like many Saturday mornings, Red Hat Bangalore office was once again abuzz with enthusiasm on 8th of April, for hosting yet another successful chapter of Bangalore Kubernetes Meetup. The Meetup had a good turnaround of about 40 people who gave up on their early morning saturday sleep to attend it despite the sweltering hot season and in line were four awesome talks.
Suraj Deshmukh set the stage with his opening talk, Kubernetes on CRI-O, wherein he explained different jargons like OCI, CRI, etc.</description>
    </item>
    
    <item>
      <title>k8s on CRI-O - single node</title>
      <link>https://suraj.io/post/using-crio-with-k8s-single-node/</link>
      <pubDate>Sat, 08 Apr 2017 00:11:37 +0530</pubDate>
      
      <guid>https://suraj.io/post/using-crio-with-k8s-single-node/</guid>
      <description>Here is a single node Kubernetes on CRI-O. This setup is done on Fedora 25.
Installing OS dependencies dnf -y install \  go \  git \  btrfs-progs-devel \  device-mapper-devel \  glib2-devel \  glibc-devel \  glibc-static \  gpgme-devel \  libassuan-devel \  libgpg-error-devel \  libseccomp-devel \  libselinux-devel \  pkgconfig \  wget \  etcd \  iptables Creating go environment cd ~ mkdir -p ~/go export GOPATH=~/go export GOBIN=$GOPATH/bin export PATH=$PATH:$GOBIN echo &amp;#39;GOPATH=~/go&amp;#39; &amp;gt;&amp;gt; ~/.</description>
    </item>
    
  </channel>
</rss>
